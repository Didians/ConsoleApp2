{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrwVQsM9TiUw"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Probability Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "CpDUTVKYTowI"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\"); { display-mode: \"form\" }\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltPJCG6pAUoc"
      },
      "source": [
        "# TFP Probabilistic Layers: Variational Auto Encoder\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/probability/examples/Probabilistic_Layers_VAE\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/probability/blob/main/tensorflow_probability/examples/jupyter_notebooks/Probabilistic_Layers_VAE.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/probability/blob/main/tensorflow_probability/examples/jupyter_notebooks/Probabilistic_Layers_VAE.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/probability/tensorflow_probability/examples/jupyter_notebooks/Probabilistic_Layers_VAE.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRVR-tGTR31S"
      },
      "source": [
        "In this example we show how to fit a Variational Autoencoder using TFP's \"probabilistic layers.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiR4-VOt9NFX"
      },
      "source": [
        "### Dependencies & Prerequisites\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if tf.test.gpu_device_name() != '/device:GPU:0':\n",
        "  print('WARNING: GPU device not found.')\n",
        "else:\n",
        "  print('SUCCESS: Found GPU: {}'.format(tf.test.gpu_device_name()))"
      ],
      "metadata": {
        "id": "SlPd774mh9qb",
        "outputId": "2679508e-c7d5-429b-8407-7e3de66f8075",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUCCESS: Found GPU: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow.compat.v2 as tf\n",
        "tf.enable_v2_behavior()\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "tfpl = tfp.layers\n",
        "tfd = tfp.distributions"
      ],
      "metadata": {
        "id": "UWmyb2YAiBeI"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if tf.test.gpu_device_name() != '/device:GPU:0':\n",
        "  print('WARNING: GPU device not found.')\n",
        "else:\n",
        "  print('SUCCESS: Found GPU: {}'.format(tf.test.gpu_device_name()))"
      ],
      "metadata": {
        "id": "yjkpPZevibFi",
        "outputId": "e4b5bb44-4d7e-4623-e46e-aa7a595ddf8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUCCESS: Found GPU: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "kZ0MdF1j8WJf"
      },
      "outputs": [],
      "source": [
        "datasets, datasets_info = tfds.load(name='mnist',\n",
        "                                    with_info=True,\n",
        "                                    as_supervised=False)\n",
        "\n",
        "def _preprocess(sample):\n",
        "  image = tf.cast(sample['image'], tf.float32) / 255.  # Scale to unit interval.\n",
        "  image = image < tf.random.uniform(tf.shape(image))   # Randomly binarize.\n",
        "  return image, image\n",
        "\n",
        "train_dataset = (datasets['train']\n",
        "                 .map(_preprocess)\n",
        "                 .batch(256)\n",
        "                 .prefetch(tf.data.AUTOTUNE)\n",
        "                 .shuffle(int(10e3)))\n",
        "eval_dataset = (datasets['test']\n",
        "                .map(_preprocess)\n",
        "                .batch(256)\n",
        "                .prefetch(tf.data.AUTOTUNE))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nnwjUdVoWN2"
      },
      "source": [
        "### Make things Fast!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2CK9RaDcoYPG"
      },
      "source": [
        "Before we dive in, let's make sure we're using a GPU for this demo.  \n",
        "\n",
        "To do this, select \"Runtime\" -> \"Change runtime type\" -> \"Hardware accelerator\" -> \"GPU\".\n",
        "\n",
        "The following snippet will verify that we have access to a GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qP_4Xr8vpA42",
        "outputId": "afc45e7a-2e66-4768-f4f7-96800077ac59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SUCCESS: Found GPU: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "if tf.test.gpu_device_name() != '/device:GPU:0':\n",
        "  print('WARNING: GPU device not found.')\n",
        "else:\n",
        "  print('SUCCESS: Found GPU: {}'.format(tf.test.gpu_device_name()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJRBc_S0ppfE"
      },
      "source": [
        "Note: if for some reason you cannot access a GPU, this colab will still work. (Training will just take longer.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8Shtn_e99XC"
      },
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "daPl6ycN9cD3"
      },
      "outputs": [],
      "source": [
        "datasets, datasets_info = tfds.load(name='mnist',\n",
        "                                    with_info=True,\n",
        "                                    as_supervised=False)\n",
        "\n",
        "def _preprocess(sample):\n",
        "  image = tf.cast(sample['image'], tf.float32) / 255.  # Scale to unit interval.\n",
        "  image = image < tf.random.uniform(tf.shape(image))   # Randomly binarize.\n",
        "  return image, image\n",
        "\n",
        "train_dataset = (datasets['train']\n",
        "                 .map(_preprocess)\n",
        "                 .batch(256)\n",
        "                 .prefetch(tf.data.AUTOTUNE)\n",
        "                 .shuffle(int(10e3)))\n",
        "eval_dataset = (datasets['test']\n",
        "                .map(_preprocess)\n",
        "                .batch(256)\n",
        "                .prefetch(tf.data.AUTOTUNE))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MtfCs9KIjEGn"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPKblOe58Hql"
      },
      "source": [
        "Note that _preprocess() above returns `image, image` rather than just `image` because Keras is set up for discriminative models with an (example, label) input format, i.e. $p_\\theta(y|x)$. Since the goal of the VAE is to recover the input x from x itself (i.e. $p_\\theta(x|x)$), the data pair is (example, example)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CI-VFyp8-BIa"
      },
      "source": [
        "### VAE Code Golf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKgRI5eoS2rx"
      },
      "source": [
        "#### Specify model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "rd3Voa64_Gtv"
      },
      "outputs": [],
      "source": [
        "input_shape = datasets_info.features['image'].shape\n",
        "encoded_size = 16\n",
        "base_depth = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "9d7Jbm66FN_u"
      },
      "outputs": [],
      "source": [
        "prior = tfd.Independent(tfd.Normal(loc=tf.zeros(encoded_size), scale=1),\n",
        "                        reinterpreted_batch_ndims=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "eRHjRtAL-e33"
      },
      "outputs": [],
      "source": [
        "input_shape = datasets_info.features['image'].shape\n",
        "encoded_size = 16\n",
        "base_depth = 32"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prior = tfd.Independent(tfd.Normal(loc=tf.zeros(encoded_size), scale=1),\n",
        "                        reinterpreted_batch_ndims=1)"
      ],
      "metadata": {
        "id": "ruH6AUVbjmIm"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "7itugvZVLyWL"
      },
      "outputs": [],
      "source": [
        "prior = tfd.Independent(tfd.Normal(loc=tf.zeros(encoded_size), scale=1),\n",
        "                        reinterpreted_batch_ndims=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ckYuzfILkVb"
      },
      "source": [
        "#### Do inference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "e7f1u-Ya-axQ"
      },
      "outputs": [],
      "source": [
        "prior = tfd.Independent(tfd.Normal(loc=tf.zeros(encoded_size), scale=1),\n",
        "                        reinterpreted_batch_ndims=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hC4rNz9t_zpo"
      },
      "source": [
        "### Look Ma, No ~~Hands~~Tensors!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZqfOYMP_2p_"
      },
      "outputs": [],
      "source": [
        "# We'll just examine ten random digits.\n",
        "x = next(iter(eval_dataset))[0][:10]\n",
        "xhat = vae(x)\n",
        "assert isinstance(xhat, tfd.Distribution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "MM7wW4S2OrBt"
      },
      "outputs": [],
      "source": [
        "#@title Image Plot Util\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def display_imgs(x, y=None):\n",
        "  if not isinstance(x, (np.ndarray, np.generic)):\n",
        "    x = np.array(x)\n",
        "  plt.ioff()\n",
        "  n = x.shape[0]\n",
        "  fig, axs = plt.subplots(1, n, figsize=(n, 1))\n",
        "  if y is not None:\n",
        "    fig.suptitle(np.argmax(y, axis=1))\n",
        "  for i in range(n):\n",
        "    axs.flat[i].imshow(x[i].squeeze(), interpolation='none', cmap='gray')\n",
        "    axs.flat[i].axis('off')\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "  plt.ion()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "ow7rfh6YLLx1",
        "outputId": "d3870f34-202c-455d-d750-4e15b54994eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Originals:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x100 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded Random Samples:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'xhat' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-145-1e5ea45466b6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Decoded Random Samples:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdisplay_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxhat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Decoded Modes:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'xhat' is not defined"
          ]
        }
      ],
      "source": [
        "print('Originals:')\n",
        "display_imgs(x)\n",
        "\n",
        "print('Decoded Random Samples:')\n",
        "display_imgs(xhat.sample())\n",
        "\n",
        "print('Decoded Modes:')\n",
        "display_imgs(xhat.mode())\n",
        "\n",
        "print('Decoded Means:')\n",
        "display_imgs(xhat.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3_5HPUCQpYO"
      },
      "outputs": [],
      "source": [
        "# Now, let's generate ten never-before-seen digits.\n",
        "z = prior.sample(10)\n",
        "xtilde = decoder(z)\n",
        "assert isinstance(xtilde, tfd.Distribution)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def display_imgs(x, y=None):\n",
        "  if not isinstance(x, (np.ndarray, np.generic)):\n",
        "    x = np.array(x)\n",
        "  plt.ioff()\n",
        "  n = x.shape[0]\n",
        "  fig, axs = plt.subplots(1, n, figsize=(n, 1))\n",
        "  if y is not None:\n",
        "    fig.suptitle(np.argmax(y, axis=1))\n",
        "  for i in range(n):\n",
        "    axs.flat[i].imshow(x[i].squeeze(), interpolation='none', cmap='gray')\n",
        "    axs.flat[i].axis('off')\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "  plt.ion()"
      ],
      "metadata": {
        "id": "d_qEfcCjl8Wb"
      },
      "execution_count": 140,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Probabilistic Layers VAE",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}